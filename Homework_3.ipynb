{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3 ADM\n",
    "### group №15 composed by Francesco Romeo, Katsiaryna Zavadskaya, Leandro B. Gentili. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 & 2: tsv documents' creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import csv\n",
    "import heapq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# utils\n",
    "from csv2dict import CSV2Dict\n",
    "from utils import normalized\n",
    "from utils import preprocessing_nltk\n",
    "from utils import compute_tfidf\n",
    "from utils import cosine_similarity\n",
    "from utils import distance_function\n",
    "\n",
    "# globals\n",
    "base_dir = './data/'\n",
    "tsv_dir = base_dir + 'tsv/'\n",
    "dataset = base_dir + 'Airbnb_Texas_Rentals.csv'\n",
    "\n",
    "# pickle store data\n",
    "pickle_location = base_dir + 'store/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As it is written in README file here we load tsv files which were created before using CSV2Dict class. The code for tsv files creation is provived in README and was used once in the very beginning to create these files. Here instead we load our previously created tsv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from pickle: ./data/store/store.pkl\n"
     ]
    }
   ],
   "source": [
    "# wrapper for csv processing\n",
    "\n",
    "# 1. dataset => is the dataset we're using\n",
    "# 2. quotechar and delimiter are two csv reader prefs\n",
    "# 3. splittsv => if None, any .tsv will be created; otherwise, for each line of the .csv a .tsv file will be \n",
    "#    created in the provided folder (tsv_dir)\n",
    "# 4. topickle => is a tuple containing the method (load or save) and the folder where to store/read a pickle file\n",
    "csv2dict = CSV2Dict(dataset, delimiter=',', quotechar='\"', splittsv=tsv_dir, topickle=('load', pickle_location))\n",
    "data = csv2dict.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### docid2words is a list of dictionaries. Each dictionary contains the number of tsv document as a key and list of all words from title and description as a value. The value list is preprocessed by preprocessing_nltk function from utils.py. The length of the docid2words list is the same as the number of tsv documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### word2id is simply a vocabulary of all the unique words from description and title of all the tsv docs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### word2docid is in fact an inverse index where for each word which is a key of dictionary we store a value e.g. a list of numbers of documents which contain this specific word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### geo2coords is also created using class csv2dict and it contains the name of the city and coordinates from the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### docid2geo keeps the id of each document and the name of the city from this document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the list of words contained in a document\n",
    "# it simply is the document content\n",
    "docid2words = data['docid2words']\n",
    "\n",
    "# vocabulary\n",
    "word2id = data['word2id']\n",
    "\n",
    "# documents that contain a precise word\n",
    "word2docid = data['word2docid']\n",
    "\n",
    "# a collection of city, coords and document id\n",
    "geo2coords = data['geo2coords']\n",
    "\n",
    "# document id related to the city name\n",
    "docid2geo = data['docid2geo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next using our inverse index which is word2docid, for each key in word2docid, which is a unique word from title and description we add tf-idf value respectively to each word for each document. Sample is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_ii = csv2dict.tfidf_inverse_index(word2docid, docid2words)\n",
    "\n",
    "# inverse index\n",
    "word2docid_tfidf = tfidf_ii['word2docid_tfidf']\n",
    "\n",
    "# docid2words_tfidf\n",
    "docid2words_tfidf = tfidf_ii['docid2words_tfidf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['privat', 'entranc', 'cozi', 'histor', 'privat', 'studio']\n",
      "{'privat': 0.18737070484602142, 'cozi': 0.13566021410161513, 'entranc': 0.23998598119244557, 'histor': 0.19322314834126833, 'studio': 0.2496669036660849}\n"
     ]
    }
   ],
   "source": [
    "# sample of content for doc №10\n",
    "print(docid2words['10'])\n",
    "print(docid2words_tfidf['10'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our next step is to create document vectors, where for each doc id -- d for each word from document d we have tfidf. As a result for each document we have a numeric vector with tf-idf values on positions of each word from vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# computing document vectors\n",
    "docid2vec = {}\n",
    "\n",
    "# empty vector\n",
    "words_voc = list(word2id.keys()) \n",
    "empty_vec = [0.0 for w in words_voc] \n",
    "\n",
    "for d, doc_words in docid2words.items():\n",
    "    \n",
    "    # shallow copy through slicing\n",
    "    docid2vec[d] = empty_vec[:]\n",
    "    \n",
    "    # putting tfidf values related to words contained\n",
    "    # in document in position i of the vector\n",
    "    for w in doc_words:\n",
    "        i = words_voc.index(w)\n",
    "        docid2vec[d][i] = docid2words_tfidf[d][w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10127\n",
      "10127\n"
     ]
    }
   ],
   "source": [
    "# length of a document vector\n",
    "# it's the same length of the vocabulary\n",
    "print(len(docid2vec['999']))\n",
    "print(len(word2id.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 : Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Asking user to put the query and preprocessing this query in the same way as title and description previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beautiful apartment downtown balcony\n",
      "['beauti', 'apart', 'downtown', 'balconi']\n"
     ]
    }
   ],
   "source": [
    "# ask user\n",
    "query = input()\n",
    "query = preprocessing_nltk(query)\n",
    "\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next we are creating query vector. We treat user query as a document from our collection, so for each word in the query we put tfidf value. This is our query vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build user input query vector\n",
    "\n",
    "# empty vector\n",
    "words_voc = list(word2id.keys()) \n",
    "uiq_vec = [0.0 for w in words_voc] \n",
    "\n",
    "# for each word in query\n",
    "for w in query:\n",
    "    \n",
    "    # if word is contained in user's query\n",
    "    # we need to push tfidf value for that word\n",
    "    i = words_voc.index(w)\n",
    "    tfidf_w = compute_tfidf(query.count(w), len(query), len(docid2words.keys()), len(word2docid[w]))\n",
    "    uiq_vec[i] = tfidf_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now when we have our query and word2docid which contains all the documents for each word, we find this list of id-documents for each word from query and intersect these lists. matching_docs is list of documents id which contain all the words from query. matching_docs is the result of our search engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "['5324', '1243', '14105', '15417', '7172', '4451', '16178', '8543', '17058']\n"
     ]
    }
   ],
   "source": [
    "# here we are taking a list of documents numbers for each word in user query and\n",
    "# intersect these lists to receive only the numbers of documents which contain ALL of these query words.\n",
    "sets = []\n",
    "\n",
    "# for each word in user's query\n",
    "for q in query:\n",
    "    \n",
    "    # get document ids containing that word or empty set()\n",
    "    sets.append(word2docid.get(q) or set())\n",
    "\n",
    "# conjunctive query (AND)\n",
    "matching_docs = list(set.intersection(*sets))\n",
    "\n",
    "# info\n",
    "print(len(matching_docs))\n",
    "print(matching_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we visualize each document which appeared in the result of our search engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5324\n",
      "Houston\n",
      "Contemporary styled apartment with a beautiful color scheme attached. Consists of 1 Bedroom (Master), Dining area, 2 balconies, Kitchen (Fully equipped), Living Room, and Bathroom with bath/shower combo and two sinks included. \\nLocated 24 miles from NRG Stadium; approximately 35 minutes away. \\nLocated 22 miles from Downtown Houston; approximately 32 minutes away.\n",
      "29.7320840939491\n",
      "-95.6537604044484\n",
      "\n",
      "1243\n",
      "Dallas\n",
      "In the heart of historic Old East Dallas, this is a beautiful 1930’s Victorian apartment house that’s as classic as it is comfortable. Relax on the big, shared upstairs balcony with a cup of coffee or glass of wine overlooking sleepy Junius Street. Find original character everywhere with modern amenities like highspeed WiFi and Amazon Fire TV w/ Netflix and Hulu. Prime location near Downtown, Deep Ellum and Lower Greenville. Cafes, shopping, nightlife and restaurants are conveniently close.\n",
      "32.7963935721254\n",
      "-96.7717690173793\n",
      "\n",
      "14105\n",
      "Dallas\n",
      "Our apartment is a cute artist get away only a few minutes from nightlife, shopping and dinning in Deep Ellum, Lower Greenville, and downtown Dallas. Whole Foods, CVS, and Starbucks are right up the street! So is the Lakewood Public Library and the Santa Fe Trail that leads you right to White Rock Lake! Enjoy the glass doors that open to a balcony overseeing the beautiful and easily accessible pool! My home is a LGBTQ and people of color affirming space.\n",
      "32.8106639925534\n",
      "-96.756590262582\n",
      "\n",
      "15417\n",
      "Austin\n",
      "Large 1-bedroom apartment in the heart of South Austin. Beautiful view of downtown from balcony! Bus stop right across the street that will take you Dowtown/Zilker/Barton Springs. Bars and restaurants within walking distance. Quiet Complex w/parking.\n",
      "30.2361541000197\n",
      "-97.7829581256141\n",
      "\n",
      "7172\n",
      "Austin\n",
      "New contemporary apartment less than a mile from beautiful Lake Austin and a 15-20 minute drive to downtown Austin. Apartment features a living area, private bedroom with full bed, new queen sofa bed, private entrance and balcony.\n",
      "30.3455405518117\n",
      "-97.8594403179482\n",
      "\n",
      "4451\n",
      "Dallas\n",
      "My apartment is a cozy artist get away only a few minutes from nightlife, shopping and dinning in Deep Ellum, Lower Greenville, and downtown Dallas. Whole Foods, CVS, and Starbucks are right up the street! So is the Lakewood Public Library and the Santa Fe Trail that leads you right to White Rock Lake! Enjoy the glass doors that open to a balcony overseeing the beautiful and easily accessible pool! My home is a LGBTQ and people of color affirming space.\n",
      "32.8085129339755\n",
      "-96.7581887202232\n",
      "\n",
      "16178\n",
      "Dallas\n",
      "My apartment is a cozy artist get away only a few minutes from nightlife, shopping and dinning in Deep Ellum, Lower Greenville, and downtown Dallas. Whole Foods, CVS, and Starbucks are right up the street! So is the Lakewood Public Library and the Santa Fe Trail that leads you right to White Rock Lake! Enjoy the glass doors that open to a balcony overseeing the beautiful and easily accessible pool! My home is a LGBTQ and people of color affirming space.\n",
      "32.8085129339755\n",
      "-96.7581887202232\n",
      "\n",
      "8543\n",
      "Austin\n",
      "Beautiful 1 bed 1 bath apartment with balcony view AND garage parking. In downtown Austin! 5 min drive from 6th Street/ Town Lake, &amp; Rainey Street. Average cost for a RideShare if you don't have a car to downtown nightlife is $6.\n",
      "30.2861570183293\n",
      "-97.7475284766327\n",
      "\n",
      "17058\n",
      "Dallas\n",
      "In the heart of historic Old East Dallas, this is a beautiful 1930’s Victorian apartment house that’s as classic as it is comfortable. Relax on the big, shared upstairs balcony with a cup of coffee or glass of wine overlooking sleepy Junius Street. Find original character everywhere with modern amenities like highspeed WiFi, Amazon Fire TV w/ Netflix and Hulu. Prime location near Downtown, Deep Ellum and Lower Greenville. Cafes, shopping, nightlife and restaurants are conveniently close.\n",
      "32.795928386191\n",
      "-96.7716865515425\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for md in matching_docs:\n",
    "    df = pd.read_csv(tsv_dir + 'doc_' + md + '.tsv', sep='\\t', usecols=[2, 4, 5, 6])\n",
    "    print(md)\n",
    "    print(df.columns[0])\n",
    "    print(df.columns[1])\n",
    "    print(df.columns[2])\n",
    "    print(df.columns[3] + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next we are calculating cosine similarity between each document from matching_docs and query vector. To do that we use scipy package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matching_docs_cos = []\n",
    "\n",
    "for d in matching_docs:\n",
    "    matching_docs_cos.append((cosine_similarity(uiq_vec, docid2vec[d]), d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then we create heap structure from list with documents' vectors. And after that we take top 10 documents according to cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.3946997927850433, '7172'), (0.29868038710081823, '8543'), (0.28160131275452094, '15417'), (0.21705066786852723, '5324'), (0.18638229010465457, '14105'), (0.16080989170544646, '17058'), (0.15479289383844108, '1243'), (0.15090774604746593, '4451'), (0.15090774604746593, '16178')]\n"
     ]
    }
   ],
   "source": [
    "# creating heap structure\n",
    "heapq.heapify(matching_docs_cos)\n",
    "\n",
    "# showing the top-k where k = 10\n",
    "topk_cos = heapq.nlargest(10, matching_docs_cos)\n",
    "print(topk_cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.3946997927850433, '7172')\n",
      "Austin\n",
      "New contemporary apartment less than a mile from beautiful Lake Austin and a 15-20 minute drive to downtown Austin. Apartment features a living area, private bedroom with full bed, new queen sofa bed, private entrance and balcony.\n",
      "30.3455405518117\n",
      "-97.8594403179482\n",
      "\n",
      "(0.29868038710081823, '8543')\n",
      "Austin\n",
      "Beautiful 1 bed 1 bath apartment with balcony view AND garage parking. In downtown Austin! 5 min drive from 6th Street/ Town Lake, &amp; Rainey Street. Average cost for a RideShare if you don't have a car to downtown nightlife is $6.\n",
      "30.2861570183293\n",
      "-97.7475284766327\n",
      "\n",
      "(0.28160131275452094, '15417')\n",
      "Austin\n",
      "Large 1-bedroom apartment in the heart of South Austin. Beautiful view of downtown from balcony! Bus stop right across the street that will take you Dowtown/Zilker/Barton Springs. Bars and restaurants within walking distance. Quiet Complex w/parking.\n",
      "30.2361541000197\n",
      "-97.7829581256141\n",
      "\n",
      "(0.21705066786852723, '5324')\n",
      "Houston\n",
      "Contemporary styled apartment with a beautiful color scheme attached. Consists of 1 Bedroom (Master), Dining area, 2 balconies, Kitchen (Fully equipped), Living Room, and Bathroom with bath/shower combo and two sinks included. \\nLocated 24 miles from NRG Stadium; approximately 35 minutes away. \\nLocated 22 miles from Downtown Houston; approximately 32 minutes away.\n",
      "29.7320840939491\n",
      "-95.6537604044484\n",
      "\n",
      "(0.18638229010465457, '14105')\n",
      "Dallas\n",
      "Our apartment is a cute artist get away only a few minutes from nightlife, shopping and dinning in Deep Ellum, Lower Greenville, and downtown Dallas. Whole Foods, CVS, and Starbucks are right up the street! So is the Lakewood Public Library and the Santa Fe Trail that leads you right to White Rock Lake! Enjoy the glass doors that open to a balcony overseeing the beautiful and easily accessible pool! My home is a LGBTQ and people of color affirming space.\n",
      "32.8106639925534\n",
      "-96.756590262582\n",
      "\n",
      "(0.16080989170544646, '17058')\n",
      "Dallas\n",
      "In the heart of historic Old East Dallas, this is a beautiful 1930’s Victorian apartment house that’s as classic as it is comfortable. Relax on the big, shared upstairs balcony with a cup of coffee or glass of wine overlooking sleepy Junius Street. Find original character everywhere with modern amenities like highspeed WiFi, Amazon Fire TV w/ Netflix and Hulu. Prime location near Downtown, Deep Ellum and Lower Greenville. Cafes, shopping, nightlife and restaurants are conveniently close.\n",
      "32.795928386191\n",
      "-96.7716865515425\n",
      "\n",
      "(0.15479289383844108, '1243')\n",
      "Dallas\n",
      "In the heart of historic Old East Dallas, this is a beautiful 1930’s Victorian apartment house that’s as classic as it is comfortable. Relax on the big, shared upstairs balcony with a cup of coffee or glass of wine overlooking sleepy Junius Street. Find original character everywhere with modern amenities like highspeed WiFi and Amazon Fire TV w/ Netflix and Hulu. Prime location near Downtown, Deep Ellum and Lower Greenville. Cafes, shopping, nightlife and restaurants are conveniently close.\n",
      "32.7963935721254\n",
      "-96.7717690173793\n",
      "\n",
      "(0.15090774604746593, '4451')\n",
      "Dallas\n",
      "My apartment is a cozy artist get away only a few minutes from nightlife, shopping and dinning in Deep Ellum, Lower Greenville, and downtown Dallas. Whole Foods, CVS, and Starbucks are right up the street! So is the Lakewood Public Library and the Santa Fe Trail that leads you right to White Rock Lake! Enjoy the glass doors that open to a balcony overseeing the beautiful and easily accessible pool! My home is a LGBTQ and people of color affirming space.\n",
      "32.8085129339755\n",
      "-96.7581887202232\n",
      "\n",
      "(0.15090774604746593, '16178')\n",
      "Dallas\n",
      "My apartment is a cozy artist get away only a few minutes from nightlife, shopping and dinning in Deep Ellum, Lower Greenville, and downtown Dallas. Whole Foods, CVS, and Starbucks are right up the street! So is the Lakewood Public Library and the Santa Fe Trail that leads you right to White Rock Lake! Enjoy the glass doors that open to a balcony overseeing the beautiful and easily accessible pool! My home is a LGBTQ and people of color affirming space.\n",
      "32.8085129339755\n",
      "-96.7581887202232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for md in topk_cos:\n",
    "    df = pd.read_csv(tsv_dir + 'doc_' + md[1] + '.tsv', sep='\\t', usecols=[2, 4, 5, 6])\n",
    "    print(md)\n",
    "    print(df.columns[0])\n",
    "    print(df.columns[1])\n",
    "    print(df.columns[2])\n",
    "    print(df.columns[3] + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4\n",
    "\n",
    "#### This is an example of how another feature of interest (Location in this case) could be combined to our previous \"ranking\" method. In fact, we could consider document cosine similarity as a good starting point to be enhanced with a new normalized index (to maintain consistency and still being able to compare the old and new ranks).\n",
    "\n",
    "#### Hence, we are going to ask user's preferred geographical position (city name) and, after computing the distances between user's position and each room ads. Considering that there's a inverse correlation between distance and the way we deal with ranking. On one hand, the higher the rank (cosine) is, the better it is. On the other hand, the lower the distance is, the better it is. For this reason, we're going to invert the normalized index obtained through distance calculations.\n",
    "\n",
    "#### The combination between this two normalized values (cosine similarity and distance) will be achieved through a weighted mean (https://en.wikipedia.org/wiki/Weighted_arithmetic_mean)\n",
    "\n",
    "#### Moreover, we decided to give more weight to distances in Step 4. Lastly, this could be considered like a small example of how much a feature could contribute to a decent ranking system, as an alternative to cut off a significant proportion of data (filtering). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Houston\n"
     ]
    }
   ],
   "source": [
    "# ask user's position to show him/her\n",
    "# the better place nearby\n",
    "u_pos = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get coords of users input\n",
    "if not u_pos in geo2coords.keys():\n",
    "    print('This city is not supported!')\n",
    "\n",
    "coords = geo2coords[u_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('29.8293522272149', '-95.0815494887563')\n"
     ]
    }
   ],
   "source": [
    "print(coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we calculate distances between each document from matching_docs and user's city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distances = []\n",
    "\n",
    "# for each matching document\n",
    "for m in matching_docs:\n",
    "    \n",
    "    # get city and its coords\n",
    "    d_city = docid2geo[m]\n",
    "    d_coords = geo2coords[d_city]\n",
    "    \n",
    "    # computing distance between user's location\n",
    "    # and each document's one\n",
    "    dist = distance_function(coords, d_coords)\n",
    "    distances.append((dist, m, d_city))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, '5324', 'Houston'), (369.64077265826234, '1243', 'Dallas'), (369.64077265826234, '14105', 'Dallas'), (261.00404694199005, '15417', 'Austin'), (261.00404694199005, '7172', 'Austin'), (369.64077265826234, '4451', 'Dallas'), (369.64077265826234, '16178', 'Dallas'), (261.00404694199005, '8543', 'Austin'), (369.64077265826234, '17058', 'Dallas')]\n",
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(distances)\n",
    "print(len(distances))\n",
    "print(len(matching_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.0, '5324', 'Houston'), (0.60763913, '1243', 'Dallas'), (0.60763913, '14105', 'Dallas'), (0.7229532, '15417', 'Austin'), (0.7229532, '7172', 'Austin'), (0.60763913, '4451', 'Dallas'), (0.60763913, '16178', 'Dallas'), (0.7229532, '8543', 'Austin'), (0.60763913, '17058', 'Dallas')]\n",
      "['5324', '1243', '14105', '15417', '7172', '4451', '16178', '8543', '17058']\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "distance_km = [x[0] for x in distances]\n",
    "\n",
    "# we need to invert the index as there's an inverse correlation\n",
    "# between the way we deal with our index from 0 to 1 and the distance \n",
    "distance_km_norm = 1.0 - normalized(np.asarray(distance_km, dtype=np.float32))\n",
    "matching_docs_dist = [(distance_km_norm[0][i], distances[i][1], distances[i][2]) for i in range(len(distances))]\n",
    "\n",
    "# index to easily access and avoid loop of loops\n",
    "\n",
    "matching_docs_dist_i = [i[1] for i in matching_docs_dist]\n",
    "\n",
    "print(matching_docs_dist)\n",
    "print(matching_docs_dist_i)\n",
    "print(len(matching_docs_dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next we are merging together our two rankings with weights 20% to cosine and 80% to distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# merge cosine_similarity and distance\n",
    "matching_docs_ni = []\n",
    "\n",
    "# combining cosine_similarity and the new index\n",
    "for md_cos in matching_docs_cos:\n",
    "    \n",
    "    # document id\n",
    "    m_cos_id = md_cos[1]\n",
    "    \n",
    "    # get cosine_similarity value\n",
    "    m_cos_val = md_cos[0]\n",
    "    \n",
    "    # get distance value\n",
    "    dist_index = matching_docs_dist_i.index(m_cos_id)\n",
    "    dist_val = matching_docs_dist[dist_index][0]\n",
    "    \n",
    "    # weighted mean value (more importance to distances)\n",
    "    mean_v = (m_cos_val * 0.2) + (dist_val * 0.8)\n",
    "    matching_docs_ni.append((mean_v, m_cos_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarly to cosine similarity, we create heap structure and receive top 10 documents according our new ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.8434101335737055, '5324'), (0.6573025188292254, '7172'), (0.6380986376923804, '8543'), (0.6346828228231209, '15417'), (0.523387765165096, '14105'), (0.5182732854852543, '17058'), (0.5170698859118533, '1243'), (0.5162928563536583, '4451'), (0.5162928563536583, '16178')]\n"
     ]
    }
   ],
   "source": [
    "# creating heap structure\n",
    "heapq.heapify(matching_docs_ni)\n",
    "\n",
    "# showing the top-k where k = 10\n",
    "topk = heapq.nlargest(10, matching_docs_ni)\n",
    "\n",
    "# info\n",
    "print(topk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation of top 10 documents according our new ranking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8434101335737055, '5324')\n",
      "Houston\n",
      "Contemporary styled apartment with a beautiful color scheme attached. Consists of 1 Bedroom (Master), Dining area, 2 balconies, Kitchen (Fully equipped), Living Room, and Bathroom with bath/shower combo and two sinks included. \\nLocated 24 miles from NRG Stadium; approximately 35 minutes away. \\nLocated 22 miles from Downtown Houston; approximately 32 minutes away.\n",
      "29.7320840939491\n",
      "-95.6537604044484\n",
      "\n",
      "(0.6573025188292254, '7172')\n",
      "Austin\n",
      "New contemporary apartment less than a mile from beautiful Lake Austin and a 15-20 minute drive to downtown Austin. Apartment features a living area, private bedroom with full bed, new queen sofa bed, private entrance and balcony.\n",
      "30.3455405518117\n",
      "-97.8594403179482\n",
      "\n",
      "(0.6380986376923804, '8543')\n",
      "Austin\n",
      "Beautiful 1 bed 1 bath apartment with balcony view AND garage parking. In downtown Austin! 5 min drive from 6th Street/ Town Lake, &amp; Rainey Street. Average cost for a RideShare if you don't have a car to downtown nightlife is $6.\n",
      "30.2861570183293\n",
      "-97.7475284766327\n",
      "\n",
      "(0.6346828228231209, '15417')\n",
      "Austin\n",
      "Large 1-bedroom apartment in the heart of South Austin. Beautiful view of downtown from balcony! Bus stop right across the street that will take you Dowtown/Zilker/Barton Springs. Bars and restaurants within walking distance. Quiet Complex w/parking.\n",
      "30.2361541000197\n",
      "-97.7829581256141\n",
      "\n",
      "(0.523387765165096, '14105')\n",
      "Dallas\n",
      "Our apartment is a cute artist get away only a few minutes from nightlife, shopping and dinning in Deep Ellum, Lower Greenville, and downtown Dallas. Whole Foods, CVS, and Starbucks are right up the street! So is the Lakewood Public Library and the Santa Fe Trail that leads you right to White Rock Lake! Enjoy the glass doors that open to a balcony overseeing the beautiful and easily accessible pool! My home is a LGBTQ and people of color affirming space.\n",
      "32.8106639925534\n",
      "-96.756590262582\n",
      "\n",
      "(0.5182732854852543, '17058')\n",
      "Dallas\n",
      "In the heart of historic Old East Dallas, this is a beautiful 1930’s Victorian apartment house that’s as classic as it is comfortable. Relax on the big, shared upstairs balcony with a cup of coffee or glass of wine overlooking sleepy Junius Street. Find original character everywhere with modern amenities like highspeed WiFi, Amazon Fire TV w/ Netflix and Hulu. Prime location near Downtown, Deep Ellum and Lower Greenville. Cafes, shopping, nightlife and restaurants are conveniently close.\n",
      "32.795928386191\n",
      "-96.7716865515425\n",
      "\n",
      "(0.5170698859118533, '1243')\n",
      "Dallas\n",
      "In the heart of historic Old East Dallas, this is a beautiful 1930’s Victorian apartment house that’s as classic as it is comfortable. Relax on the big, shared upstairs balcony with a cup of coffee or glass of wine overlooking sleepy Junius Street. Find original character everywhere with modern amenities like highspeed WiFi and Amazon Fire TV w/ Netflix and Hulu. Prime location near Downtown, Deep Ellum and Lower Greenville. Cafes, shopping, nightlife and restaurants are conveniently close.\n",
      "32.7963935721254\n",
      "-96.7717690173793\n",
      "\n",
      "(0.5162928563536583, '4451')\n",
      "Dallas\n",
      "My apartment is a cozy artist get away only a few minutes from nightlife, shopping and dinning in Deep Ellum, Lower Greenville, and downtown Dallas. Whole Foods, CVS, and Starbucks are right up the street! So is the Lakewood Public Library and the Santa Fe Trail that leads you right to White Rock Lake! Enjoy the glass doors that open to a balcony overseeing the beautiful and easily accessible pool! My home is a LGBTQ and people of color affirming space.\n",
      "32.8085129339755\n",
      "-96.7581887202232\n",
      "\n",
      "(0.5162928563536583, '16178')\n",
      "Dallas\n",
      "My apartment is a cozy artist get away only a few minutes from nightlife, shopping and dinning in Deep Ellum, Lower Greenville, and downtown Dallas. Whole Foods, CVS, and Starbucks are right up the street! So is the Lakewood Public Library and the Santa Fe Trail that leads you right to White Rock Lake! Enjoy the glass doors that open to a balcony overseeing the beautiful and easily accessible pool! My home is a LGBTQ and people of color affirming space.\n",
      "32.8085129339755\n",
      "-96.7581887202232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for md in topk:\n",
    "    df = pd.read_csv(tsv_dir + 'doc_' + md[1] + '.tsv', sep='\\t', usecols=[2, 4, 5, 6])\n",
    "    print(md)\n",
    "    print(df.columns[0])\n",
    "    print(df.columns[1])\n",
    "    print(df.columns[2])\n",
    "    print(df.columns[3] + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
